# Airflow ETL + DQ (S3 → PostgreSQL)

## Описание задания

Реализовать два DAG в Apache Airflow:

1 - раз в час читать один новый Parquet-файл из MinIO (S3) и загружать данные в таблицу PostgreSQL.

2 - раз в час проверять качество данных по критерию совпадения количества строк в исходном файле и в загруженных данных. 
	Результат сохранять в техническую таблицу PostgreSQL.

---

## Общая логика работы

Окружение поднимается в Docker (PostgreSQL, MinIO, Airflow).
Первый DAG загружает данные из одного ранее не обработанного Parquet-файла в таблицу web_logs_loaded.
Второй DAG берёт загруженный, но ещё не проверенный файл, считает количество строк в Parquet и в PostgreSQL (по source_file) и
сравнивает значения.
Статус обработки файлов и результаты проверки сохраняются в таблицу file_status.